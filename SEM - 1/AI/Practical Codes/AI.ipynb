{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVIwmj0WBoX/quFDXKzcc6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlkRF52lEe23","executionInfo":{"status":"ok","timestamp":1763523023234,"user_tz":-330,"elapsed":3167,"user":{"displayName":"Aastha Thakker","userId":"05632659073420520532"}},"outputId":"5727645e-d82d-4f35-95be-d94d8cf53337"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 rows of the dataset:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","0                5.1               3.5                1.4               0.2   \n","1                4.9               3.0                1.4               0.2   \n","2                4.7               3.2                1.3               0.2   \n","3                4.6               3.1                1.5               0.2   \n","4                5.0               3.6                1.4               0.2   \n","\n","   target  \n","0       0  \n","1       0  \n","2       0  \n","3       0  \n","4       0  \n","\n","Shape of the dataset (rows, columns):\n","(150, 5)\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","\n","# Exercise 1: Load Dataset\n","iris = load_iris()\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","df['target'] = iris.target  # Add target variable (species)\n","\n","# Exercise 2: View Top Rows\n","print(\"First 5 rows of the dataset:\")\n","print(df.head())\n","\n","# Exercise 3: Check Shape\n","print(\"\\nShape of the dataset (rows, columns):\")\n","print(df.shape)\n"]},{"cell_type":"markdown","source":["Explanation of chunksize and DataFrame\n","DataFrame in Pandas:\n","\n","A DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). It is one of the most important structures in the Pandas library for data analysis.\n","\n","A DataFrame can hold data of different types (e.g., integers, floats, strings), and it is similar to a table or spreadsheet.\n","\n","Common operations you can perform on a DataFrame include:\n","\n","Indexing, slicing, and selecting subsets of data.\n","\n","Summarizing data (mean, sum, count, etc.).\n","\n","Handling missing values.\n","\n","Grouping, merging, and reshaping data.\n","\n","For example, in the code above, df is a DataFrame that contains the Iris dataset's features and the target variable.\n","\n","chunksize in Pandas:\n","\n","chunksize is an argument you can pass to functions like pandas.read_csv() or pandas.read_sql() when you're working with large datasets that might not fit into memory all at once.\n","\n","When you specify a chunksize, Pandas reads the file in chunks (batches) of a specified number of rows. Instead of loading the entire file into memory, it loads the data in smaller, manageable pieces.\n","\n","For example, if you're reading a CSV file with millions of rows, you might not want to load the entire file into memory at once. Instead, you can specify a chunksize to read and process the data in parts."],"metadata":{"id":"pdhqTqVpKeA2"}},{"cell_type":"code","source":["# Exercise 4: Print all column names\n","print(\"Column names:\")\n","print(df.columns)\n","\n","# Exercise 5: Data Info\n","print(\"\\nData info (data types, non-null counts, etc.):\")\n","df.info()\n","\n","# Exercise 6: Summary Statistics\n","print(\"\\nSummary statistics of the numerical columns:\")\n","print(df.describe())\n","\n","# Exercise 7: Missing Value Check\n","print(\"\\nMissing values in each column:\")\n","print(df.isnull().sum())\n","\n","# Exercise 8: Select the first 10 rows using iloc\n","print(\"\\nFirst 10 rows using iloc:\")\n","print(df.iloc[:10])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTyNRZilL6cd","executionInfo":{"status":"ok","timestamp":1763523520875,"user_tz":-330,"elapsed":78,"user":{"displayName":"Aastha Thakker","userId":"05632659073420520532"}},"outputId":"954465d0-a72b-45f4-f038-2f9d1fec87e6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Column names:\n","Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n","       'petal width (cm)', 'target'],\n","      dtype='object')\n","\n","Data info (data types, non-null counts, etc.):\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 150 entries, 0 to 149\n","Data columns (total 5 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   sepal length (cm)  150 non-null    float64\n"," 1   sepal width (cm)   150 non-null    float64\n"," 2   petal length (cm)  150 non-null    float64\n"," 3   petal width (cm)   150 non-null    float64\n"," 4   target             150 non-null    int64  \n","dtypes: float64(4), int64(1)\n","memory usage: 6.0 KB\n","\n","Summary statistics of the numerical columns:\n","       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n","count         150.000000        150.000000         150.000000   \n","mean            5.843333          3.057333           3.758000   \n","std             0.828066          0.435866           1.765298   \n","min             4.300000          2.000000           1.000000   \n","25%             5.100000          2.800000           1.600000   \n","50%             5.800000          3.000000           4.350000   \n","75%             6.400000          3.300000           5.100000   \n","max             7.900000          4.400000           6.900000   \n","\n","       petal width (cm)      target  \n","count        150.000000  150.000000  \n","mean           1.199333    1.000000  \n","std            0.762238    0.819232  \n","min            0.100000    0.000000  \n","25%            0.300000    0.000000  \n","50%            1.300000    1.000000  \n","75%            1.800000    2.000000  \n","max            2.500000    2.000000  \n","\n","Missing values in each column:\n","sepal length (cm)    0\n","sepal width (cm)     0\n","petal length (cm)    0\n","petal width (cm)     0\n","target               0\n","dtype: int64\n","\n","First 10 rows using iloc:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","0                5.1               3.5                1.4               0.2   \n","1                4.9               3.0                1.4               0.2   \n","2                4.7               3.2                1.3               0.2   \n","3                4.6               3.1                1.5               0.2   \n","4                5.0               3.6                1.4               0.2   \n","5                5.4               3.9                1.7               0.4   \n","6                4.6               3.4                1.4               0.3   \n","7                5.0               3.4                1.5               0.2   \n","8                4.4               2.9                1.4               0.2   \n","9                4.9               3.1                1.5               0.1   \n","\n","   target  \n","0       0  \n","1       0  \n","2       0  \n","3       0  \n","4       0  \n","5       0  \n","6       0  \n","7       0  \n","8       0  \n","9       0  \n"]}]},{"cell_type":"markdown","source":["**Exercise 4: Print All Column Names**\n","\n","To print the column names of the DataFrame, we can use the df.columns attribute. This will give us a list of the names of all the columns in the DataFrame.\n","\n","**Exercise 5: Data Info**\n","\n","The df.info() method provides a concise summary of the DataFrame, including the data types of each column, the number of non-null values, and the memory usage. This is useful for getting an overview of the dataset and understanding its structure.\n","\n","**Exercise 6: Summary Statistics**\n","\n","The df.describe() method generates summary statistics for numerical columns in the DataFrame, such as the count, mean, standard deviation, min, max, and quartiles (25%, 50%, 75%). This is helpful to get a quick statistical summary of the data.\n","\n","**Exercise 7: Missing Value Check**\n","\n","To check for missing values in the DataFrame, df.isnull().sum() can be used. This will return the number of missing (null) values in each column.\n","\n","**Exercise 8: Select Rows Using iloc**\n","\n","The iloc[] function is used to select rows by their integer index position. To select the first 10 rows, we use df.iloc[:10], which selects rows from position 0 to 9."],"metadata":{"id":"v47N5SEPMs7b"}},{"cell_type":"code","source":["# Exercise 9: Select Columns (numeric features only)\n","numeric_features = df.iloc[:, :-1]  # All rows, all columns except the last one (target column)\n","print(\"\\nNumeric feature columns:\")\n","print(numeric_features.head())\n","\n","# Exercise 10: Filter Data (petal length > 1.5)\n","filtered_data = df[df['petal length (cm)'] > 1.5]\n","print(\"\\nFiltered data (petal length > 1.5):\")\n","print(filtered_data.head())\n","\n","# Exercise 11: Sort Data (sort by sepal length in descending order)\n","sorted_data = df.sort_values(by='sepal length (cm)', ascending=False)\n","print(\"\\nData sorted by sepal length (descending):\")\n","print(sorted_data.head())\n","\n","# Exercise 12: Create New Column (petal_ratio)\n","df['petal_ratio'] = df['petal length (cm)'] / df['petal width (cm)']\n","print(\"\\nData with new 'petal_ratio' column:\")\n","print(df[['petal length (cm)', 'petal width (cm)', 'petal_ratio']].head())\n","\n","# Exercise 13: Drop a Column ('petal_ratio')\n","df = df.drop(columns=['petal_ratio'])\n","print(\"\\nData after dropping 'petal_ratio' column:\")\n","print(df.head())\n","\n","# Exercise 14: Convert Target to DataFrame (Separate target column)\n","y = df['target']  # This is now a separate Series\n","df = df.drop(columns=['target'])  # Remove the 'target' column from the main DataFrame\n","print(\"\\nDataFrame without 'target' column and separate 'y' DataFrame:\")\n","print(df.head())\n","print(\"\\nSeparate 'y' DataFrame:\")\n","print(y.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ug460Pn5MsFD","executionInfo":{"status":"ok","timestamp":1763523785238,"user_tz":-330,"elapsed":45,"user":{"displayName":"Aastha Thakker","userId":"05632659073420520532"}},"outputId":"fb4a5d7e-1f74-484f-82c6-fe5dddce8e39"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Numeric feature columns:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                5.1               3.5                1.4               0.2\n","1                4.9               3.0                1.4               0.2\n","2                4.7               3.2                1.3               0.2\n","3                4.6               3.1                1.5               0.2\n","4                5.0               3.6                1.4               0.2\n","\n","Filtered data (petal length > 1.5):\n","    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","5                 5.4               3.9                1.7               0.4   \n","11                4.8               3.4                1.6               0.2   \n","18                5.7               3.8                1.7               0.3   \n","20                5.4               3.4                1.7               0.2   \n","23                5.1               3.3                1.7               0.5   \n","\n","    target  \n","5        0  \n","11       0  \n","18       0  \n","20       0  \n","23       0  \n","\n","Data sorted by sepal length (descending):\n","     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","131                7.9               3.8                6.4               2.0   \n","122                7.7               2.8                6.7               2.0   \n","118                7.7               2.6                6.9               2.3   \n","117                7.7               3.8                6.7               2.2   \n","135                7.7               3.0                6.1               2.3   \n","\n","     target  \n","131       2  \n","122       2  \n","118       2  \n","117       2  \n","135       2  \n","\n","Data with new 'petal_ratio' column:\n","   petal length (cm)  petal width (cm)  petal_ratio\n","0                1.4               0.2          7.0\n","1                1.4               0.2          7.0\n","2                1.3               0.2          6.5\n","3                1.5               0.2          7.5\n","4                1.4               0.2          7.0\n","\n","Data after dropping 'petal_ratio' column:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","0                5.1               3.5                1.4               0.2   \n","1                4.9               3.0                1.4               0.2   \n","2                4.7               3.2                1.3               0.2   \n","3                4.6               3.1                1.5               0.2   \n","4                5.0               3.6                1.4               0.2   \n","\n","   target  \n","0       0  \n","1       0  \n","2       0  \n","3       0  \n","4       0  \n","\n","DataFrame without 'target' column and separate 'y' DataFrame:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                5.1               3.5                1.4               0.2\n","1                4.9               3.0                1.4               0.2\n","2                4.7               3.2                1.3               0.2\n","3                4.6               3.1                1.5               0.2\n","4                5.0               3.6                1.4               0.2\n","\n","Separate 'y' DataFrame:\n","0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","Name: target, dtype: int64\n"]}]},{"cell_type":"markdown","source":["**Exercise 9: Select Columns (Using iloc to select numeric feature columns)**\n","\n","In this exercise, we'll use iloc to select only the numeric feature columns (i.e., the first four columns: 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)').\n","\n","We'll do this by specifying the column indices in iloc to select the first four columns.\n","\n","**Exercise 10: Filter Data (Filter rows where petal length > 1.5)**\n","\n","We'll use boolean indexing to filter rows based on the condition where the 'petal length (cm)' is greater than 1.5.\n","\n","**Exercise 11: Sort Data (Sort by sepal length in descending order)**\n","\n","We'll use sort_values() to sort the dataset based on the 'sepal length (cm)' column in descending order.\n","\n","**Exercise 12: Create New Column (petal_ratio)**\n","\n","We'll create a new column called 'petal_ratio', which is the ratio of 'petal length (cm)' to 'petal width (cm)'.\n","\n","**Exercise 13: Drop a Column**\n","\n","After creating the new column, we'll drop it using drop().\n","\n","**Exercise 14: Convert Target to DataFrame**\n","\n","We'll convert the target column ('target') into a separate DataFrame and add it as a new column in the original DataFrame (df)."],"metadata":{"id":"VtWBYqljNOgj"}},{"cell_type":"code","source":["# Re-initialize df to ensure 'target' column is present for all exercises in this cell\n","# This is necessary because 'target' was dropped from df in the previous cell (Exercise 14).\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","iris = load_iris()\n","df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","df['target'] = iris.target\n","\n","# Exercise 15: Select X and y for ML\n","X = df.iloc[:, :-1]  # Features: all rows, all columns except the last one (target column)\n","y = df['target']     # Target: the 'target' column\n","print(\"\\nFeatures (X):\")\n","print(X.head())\n","print(\"\\nTarget (y):\")\n","print(y.head())\n","\n","# Exercise 16: Correlation Matrix\n","correlation_matrix = df.iloc[:, :-1].corr()  # We exclude 'target' when calculating correlation\n","print(\"\\nCorrelation Matrix of feature columns:\")\n","print(correlation_matrix)\n","\n","# Exercise 17: Unique Values Count\n","unique_classes = df['target'].unique()\n","print(\"\\nUnique target classes:\")\n","print(unique_classes)\n","\n","# Exercise 18: GroupBy (Group data by target class and compute average petal length)\n","average_petal_length_by_class = df.groupby('target')['petal length (cm)'].mean()\n","print(\"\\nAverage petal length by target class:\")\n","print(average_petal_length_by_class)\n","\n","# Exercise 19: Duplicate Check\n","duplicate_rows = df.duplicated().sum()  # Count of duplicate rows\n","print(\"\\nCount of duplicate rows:\", duplicate_rows)\n","\n","# Remove duplicate rows\n","df_cleaned = df.drop_duplicates()\n","print(\"\\nData after removing duplicates:\")\n","print(df_cleaned.head())\n","\n","# Exercise 20: Export Clean Data (Save the final DataFrame to CSV)\n","df_cleaned.to_csv('iris_cleaned.csv', index=False)\n","print(\"\\nCleaned data saved to 'iris_cleaned.csv'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DurBCwc2SV1W","executionInfo":{"status":"ok","timestamp":1763525297780,"user_tz":-330,"elapsed":58,"user":{"displayName":"Aastha Thakker","userId":"05632659073420520532"}},"outputId":"c3a50258-82fd-4c15-eb63-bcdb77261969"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Features (X):\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                5.1               3.5                1.4               0.2\n","1                4.9               3.0                1.4               0.2\n","2                4.7               3.2                1.3               0.2\n","3                4.6               3.1                1.5               0.2\n","4                5.0               3.6                1.4               0.2\n","\n","Target (y):\n","0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","Name: target, dtype: int64\n","\n","Correlation Matrix of feature columns:\n","                   sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n","sepal length (cm)           1.000000         -0.117570           0.871754   \n","sepal width (cm)           -0.117570          1.000000          -0.428440   \n","petal length (cm)           0.871754         -0.428440           1.000000   \n","petal width (cm)            0.817941         -0.366126           0.962865   \n","\n","                   petal width (cm)  \n","sepal length (cm)          0.817941  \n","sepal width (cm)          -0.366126  \n","petal length (cm)          0.962865  \n","petal width (cm)           1.000000  \n","\n","Unique target classes:\n","[0 1 2]\n","\n","Average petal length by target class:\n","target\n","0    1.462\n","1    4.260\n","2    5.552\n","Name: petal length (cm), dtype: float64\n","\n","Count of duplicate rows: 1\n","\n","Data after removing duplicates:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","0                5.1               3.5                1.4               0.2   \n","1                4.9               3.0                1.4               0.2   \n","2                4.7               3.2                1.3               0.2   \n","3                4.6               3.1                1.5               0.2   \n","4                5.0               3.6                1.4               0.2   \n","\n","   target  \n","0       0  \n","1       0  \n","2       0  \n","3       0  \n","4       0  \n","\n","Cleaned data saved to 'iris_cleaned.csv'\n"]}]},{"cell_type":"markdown","source":["Exercise 15: Select X and y for ML (Using iloc to extract all features and target)\n","\n","In this exercise, we'll use iloc to select all the feature columns (X) and the target column (y). We want to:\n","\n","Extract the features as X (all columns except target).\n","\n","Extract the target variable as y (only the target column).\n","\n","Exercise 16: Correlation Matrix (Print correlation matrix of feature columns)\n","\n","A correlation matrix helps to understand how the features relate to each other. We'll use .corr() to compute the pairwise correlation of the feature columns in the dataset.\n","\n","Exercise 17: Unique Values Count (Print unique target classes)\n","\n","We will use df['target'].unique() to display the unique values in the target column, which represents the classes of the Iris dataset (i.e., the species).\n","\n","Exercise 18: GroupBy (Group data by target class and compute average petal length)\n","\n","We'll use groupby() to group the data by the target column (which represents the species). After grouping, we'll calculate the mean of petal length for each species.\n","\n","Exercise 19: Duplicate Check (Show count of duplicate rows and remove them)\n","\n","We'll use df.duplicated() to identify duplicate rows, count them, and then remove those duplicates using df.drop_duplicates().\n","\n","Exercise 20: Export Clean Data (Save the final DataFrame to CSV)\n","\n","Finally, we'll export the cleaned DataFrame (without the target column) to a CSV file using the to_csv() method."],"metadata":{"id":"FEHcOTljSUd_"}},{"cell_type":"code","source":["# Kaggle trying\n","\n","import pandas as pd\n","\n","# Load dataset\n","df = pd.read_csv(\"path_to_file.csv\")\n","\n","# Check the first few rows\n","print(df.head())\n","\n","# Check data types and missing values\n","print(df.info())\n","\n","# Summary statistics for numeric columns\n","print(df.describe())\n","\n","\n","\n","# Check for missing values\n","print(df.isnull().sum())\n","\n","# Example: Fill missing values with the mean (for numerical columns)\n","df.fillna(df.mean(), inplace=True)\n","\n","\n","# Convert categorical columns to numeric (if applicable)\n","df['protocol'] = df['protocol'].astype('category').cat.codes\n","\n","\n","df['attack_type'] = df['attack_type'].map({'Benign': 0, 'Malicious': 1})\n","\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","numeric_columns = ['source_port', 'destination_port', 'packet_size']  # example numerical columns\n","df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Define features (X) and target (y)\n","X = df.drop('attack_type', axis=1)  # features\n","y = df['attack_type']               # target\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Initialize Random Forest Classifier\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Confusion Matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\\n\", cm)\n","\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define parameter grid for RandomForestClassifier\n","param_grid = {\n","    'n_estimators': [100, 200],\n","    'max_depth': [10, 20, None],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2]\n","}\n","\n","grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=3, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters found by GridSearchCV\n","print(\"Best parameters:\", grid_search.best_params_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","\n","import joblib\n","\n","# Save the trained model to a file\n","joblib.dump(best_model, 'cybersecurity_model.pkl')\n","\n","# Load the model for inference later\n","model = joblib.load('cybersecurity_model.pkl')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"_HQjSG5zXfw6","executionInfo":{"status":"error","timestamp":1763526486361,"user_tz":-330,"elapsed":28,"user":{"displayName":"Aastha Thakker","userId":"05632659073420520532"}},"outputId":"9eb422da-9da7-4455-fe44-795582509cfd"},"execution_count":6,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'path_to_file.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1688623539.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path_to_file.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Check the first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_file.csv'"]}]}]}